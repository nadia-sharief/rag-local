# RAG Local (Ollama)

## Prereqs
- Install Ollama and pull a model:
- Python 3.10+ (works in WSL Ubuntu or native Linux/macOS/Windows)

## Setup

## Config

## (Optional) Ingest sample data

## Run

## Test

## Notes
- The server calls Ollama at OLLAMA_BASE (default http://127.0.0.1:11434).
- Change model by setting MODEL in .env.
